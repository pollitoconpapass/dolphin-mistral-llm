# Dolphin-Mistral LLM: Local Implementation ğŸ¬ğŸ‡«ğŸ‡·

Local implementation of the Dolphin-Mistral LLM using Ollama and Chainlit

## ğŸ—‚ï¸ Prerequisites
- Ollama installed

## âš™ï¸ Installation and Running
1. Install Dolphin-Mistral from Ollama [here](https://ollama.com/library/dolphin-mistral)
2. Install all the requirements running: `pip install -r requirements.txt`
3. Run the app! `chainlit run app.py --port 5554`


## ğŸ¬ Demo 
![alt text](demo.png)
